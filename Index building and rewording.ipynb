{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import re\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
        "from tokenizers.decoders import WordPiece\n",
        "\n",
        "# Load model\n",
        "model_name = \"avichr/heBERT_NER\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForTokenClassification.from_pretrained(model_name)\n",
        "ner_pipeline = pipeline(\"ner\", model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\")\n",
        "\n",
        "oracle = pipeline('ner', model='dicta-il/dictabert-ner', aggregation_strategy='simple')\n",
        "oracle.tokenizer.backend_tokenizer.decoder = WordPiece()\n",
        "\n",
        "# Load uploaded file\n",
        "df = pd.read_csv(\"/content/true_positive_label_no.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1nZVY8xBpQDc",
        "outputId": "0de50af9-95c8-4d03-ed6a-8de01a56dd2f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n",
            "Device set to use cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define intent templates\n",
        "intent_templates = {\n",
        "    \"transport_query\": \"את יכולה למצוא לי מסלול {origin} {destination} ב{mode}?\",\n",
        "    \"alarm_set\": \"את יכולה לכוון שעון מעורר לשעה {time} ב{period}?\",\n",
        "    \"call_contact\": \"את יכולה לחייג {contact_name}?\",\n",
        "    \"send_message\": \"את יכולה לשלוח הודעה {message} {contact_name}?\",\n",
        "    \"calendar_set\": \"את יכולה ליצור לי פגישה ביומן בתאריך {date} לשעה {time}?\",\n",
        "    \"camera_query\": \"אני רוצה לצלם {type}\",\n",
        "    \"lists_createoradd\": \"תיצרי לי רשימה שיהיה בה {items}\",\n",
        "    \"weather_query\": \"מה מזג האוויר {date} {location}?\",\n",
        "    \"iot_wemo_on\": \"אני רוצה להדליק {device}\",\n",
        "    \"query\": \"את יכולה לבדוק ולהגיד לי {search string}?\"\n",
        "}\n",
        "\n",
        "# Extract keys from templates\n",
        "intent_keys = {\n",
        "    intent: re.findall(r\"{(.*?)}\", template)\n",
        "    for intent, template in intent_templates.items()\n",
        "}\n",
        "\n",
        "# Helper functions\n",
        "def extract_entities(ner_result, label):\n",
        "    return [entity[\"word\"] for entity in ner_result if label in entity[\"entity_group\"]]\n",
        "\n",
        "def extract_entity(ner_result, label):\n",
        "    entities = extract_entities(ner_result, label)\n",
        "    return entities[0] if entities else None\n"
      ],
      "metadata": {
        "id": "8KqUgvQ6dKyq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "def extract_destination_fallback(transcript):\n",
        "    words = transcript.split()\n",
        "    ignored_starters = {\"להגיע\", \"ללכת\", \"לנסוע\", \"לעלות\", \"לרדת\", \"לנסיעה\"}\n",
        "    stopwords = {\n",
        "        \"ש\", \"אם\", \"אז\", \"אבל\", \"ואם\", \"או\", \"על\", \"של\", \"עם\", \"שבו\", \"ב\",\n",
        "        \"האם\", \"איך\", \"תגידי\", \"תגיד\", \"תגידו\", \"תוכלי\", \"תוכל\", \"לעזור\", \"לי\", \"בבקשה\", \"אתה\", \"אני\", \"אולי\"\n",
        "    }\n",
        "\n",
        "    for i, word in enumerate(words):\n",
        "        # התחלה תקינה ב-\"ל\", לא פועל\n",
        "        if word.startswith(\"ל\") and word not in ignored_starters and len(word) > 2:\n",
        "            dest_words = [word]\n",
        "            number_found = False\n",
        "            for next_word in words[i+1:]:\n",
        "                # עצור אם זו מילת עצירה (גם אם לא היה מספר)\n",
        "                if next_word in stopwords:\n",
        "                    break\n",
        "                # תוודא שהמספר (למשל 45) ייכנס גם אם אחריו עיר\n",
        "                dest_words.append(next_word)\n",
        "                if re.match(r\"^\\d+$\", next_word):\n",
        "                    number_found = True\n",
        "            return \" \".join(dest_words)\n",
        "    return \"\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def build_action_json(transcript, ner_result, intent):\n",
        "    intent = intent.strip()\n",
        "    keys = intent_keys.get(intent, [])\n",
        "    result = {\"intent\": intent}\n",
        "\n",
        "    # Extract entities\n",
        "    full_name = extract_entity(ner_result, \"PER\")\n",
        "    location = extract_entity(ner_result, \"LOC\")\n",
        "    date = extract_entity(ner_result, \"DATE\")\n",
        "    time = extract_entity(ner_result, \"TIME\")\n",
        "    locs = extract_entities(ner_result, \"LOC\")\n",
        "    msg = transcript.split(\":\")[-1] if \":\" in transcript else transcript.split(full_name)[-1].strip() if full_name and full_name in transcript else None\n",
        "\n",
        "    for key in keys:\n",
        "        if intent == \"transport_query\":\n",
        "            result[\"mode\"] = \"רכב\"\n",
        "            result[\"destination\"] = \"\"\n",
        "            result[\"origin\"] = \"מהמיקום שלי\"\n",
        "\n",
        "            modes = {\n",
        "                (\"רכבת\", \"אוטובוס\"): \"תחבורה ציבורית\",\n",
        "                (\"רגל\", \"הלכ\"): \"רגל\"\n",
        "            }\n",
        "\n",
        "            for mode in modes:\n",
        "                for transport in mode:\n",
        "                    regex = rf\"{transport}\"\n",
        "                    if re.search(regex, transcript):\n",
        "                        result[\"mode\"] = modes[mode]\n",
        "                        continue\n",
        "\n",
        "            ner_result = oracle(transcript)\n",
        "\n",
        "            allowed_ents = [\"GPE\", \"FAC\", \"PER\", \"CARDINAL\", \"NUMBER\", \"LOC\"]\n",
        "            to_regex = r\"^ל\"\n",
        "            from_regex = r\"^מ\"\n",
        "\n",
        "            prev_state = None\n",
        "            destination_words = []\n",
        "            origin_words = []\n",
        "\n",
        "            for res in ner_result:\n",
        "                extracted_word = transcript[res['start']:min(res['end'] + 1, len(transcript))].strip()\n",
        "                entity = res['entity_group']\n",
        "\n",
        "                if entity in allowed_ents:\n",
        "                    if re.search(to_regex, extracted_word) and not destination_words:\n",
        "                        destination_words.append(extracted_word)\n",
        "                        prev_state = \"destination\"\n",
        "                    elif re.search(from_regex, extracted_word) and not origin_words:\n",
        "                        origin_words.append(extracted_word)\n",
        "                        prev_state = \"origin\"\n",
        "                    elif prev_state == \"destination\":\n",
        "                        destination_words.append(extracted_word)\n",
        "                    elif prev_state == \"origin\":\n",
        "                        origin_words.append(extracted_word)\n",
        "                else:\n",
        "                    prev_state = None\n",
        "\n",
        "            if destination_words:\n",
        "                result[\"destination\"] = \" \".join(destination_words)\n",
        "            if origin_words:\n",
        "                result[\"origin\"] = \" \".join(origin_words) or \"מהמיקום שלי\"\n",
        "\n",
        "            # fallback לזיהוי כתובת אם NER לא הצליח\n",
        "            if not result[\"destination\"]:\n",
        "                fallback_address = extract_destination_fallback(transcript)\n",
        "                if fallback_address:\n",
        "                    result[\"destination\"] = fallback_address\n",
        "\n",
        "        elif key == \"period\":\n",
        "            if time:\n",
        "                try:\n",
        "                    hour = int(time.split(\":\")[0])\n",
        "                    if 5 <= hour < 12:\n",
        "                        result[key] = \"בבוקר\"\n",
        "                    elif 12 <= hour < 17:\n",
        "                        result[key] = \"בצהריים\"\n",
        "                    else:\n",
        "                        result[key] = \"בערב\"\n",
        "                except:\n",
        "                    result[key] = None\n",
        "\n",
        "        elif key == \"contact_name\":\n",
        "            match_contact = re.search(r\"את\\s+([\\w\\-׳״\\\"]+(?:\\s[\\w\\-׳״\\\"]+)?)\", transcript)\n",
        "            if match_contact:\n",
        "                result[key] = match_contact.group(1).strip()\n",
        "            elif full_name:\n",
        "                result[key] = full_name.split()[0]\n",
        "            else:\n",
        "                result[key] = None\n",
        "\n",
        "        elif key == \"message\":\n",
        "            result[key] = msg\n",
        "\n",
        "        elif key == \"time\":\n",
        "            match_time = re.search(r\"(?<=בשעה )[^ ]+( [^ ]+)?\", transcript)\n",
        "            if match_time:\n",
        "                result[key] = match_time.group(0).strip()\n",
        "            else:\n",
        "                result[key] = time or (\"עוד שעתיים\" if \"עוד שעתיים\" in transcript else None)\n",
        "\n",
        "        elif key == \"date\":\n",
        "            if intent == \"weather_query\":\n",
        "                result[key] = date or \"היום\"\n",
        "            else:\n",
        "                match_date = re.search(r\"(בחמישי(?: [^ ]+)*?) (?=בשעה|שעה|תור)\", transcript)\n",
        "                if match_date:\n",
        "                    result[key] = match_date.group(1).strip()\n",
        "                else:\n",
        "                    result[key] = date or (\"5/5\" if \"חמישי לחמישי\" in transcript else None)\n",
        "\n",
        "        elif key == \"items\":\n",
        "            match = re.search(r\"(?:של|שכתוב|שיהיה)[^ ]*\\s+(.*)\", transcript)\n",
        "            raw_items = match.group(1) if match else transcript\n",
        "\n",
        "            garbage_phrases = [\n",
        "                \"סירי\", \"היי\", \"אני רוצה\", \"תכתבי\", \"שתכתבי\", \"תכתוב\", \"תיצרי\", \"בה\", \"בו\", \"בים\", \"תעשי\", \"תעשה\",\n",
        "                \"תוסיפי\", \"לי\", \"חדש\", \"פתק\", \"פתקים\", \"בפתקים\", \"בפתק\"\n",
        "            ]\n",
        "            for phrase in garbage_phrases:\n",
        "                raw_items = raw_items.replace(phrase, \"\")\n",
        "\n",
        "            parts = re.split(r\"\\s+ו\\s+|,|\\s+ו(?=\\S)\", raw_items)\n",
        "            cleaned = [p.strip(\" ,.-\") for p in parts if len(p.strip()) > 1]\n",
        "\n",
        "            if len(cleaned) > 1:\n",
        "                result[key] = \", \".join(cleaned[:-1]) + \" ו\" + cleaned[-1]\n",
        "            elif cleaned:\n",
        "                result[key] = cleaned[0]\n",
        "            else:\n",
        "                result[key] = None\n",
        "\n",
        "        elif key == \"type\":\n",
        "            if \"סלפי\" in transcript or re.search(r\"\\bה?מצלמה( הקדמית)?\\b\", transcript):\n",
        "                result[key] = \"סלפי\"\n",
        "            else:\n",
        "                result[key] = \"תמונה\"\n",
        "\n",
        "        elif key == \"location\":\n",
        "            result[key] = location or (\"תל אביב\" if \"תל אביב\" in transcript else None)\n",
        "\n",
        "        elif key == \"device\":\n",
        "            result[key] = \"מצב טיסה\" if \"מצב טיסה\" in transcript else \"התקן\"\n",
        "\n",
        "        elif key == \"search string\":\n",
        "            result[key] = transcript\n",
        "\n",
        "    return result\n",
        "\n",
        "# Extract intent_json\n",
        "intent_jsons = []\n",
        "for index, row in df.iterrows():\n",
        "    transcript = row[\"transcript_hebrew\"]\n",
        "    intent = row[\"intent\"]\n",
        "    try:\n",
        "        ner_result = ner_pipeline(transcript)\n",
        "        json_obj = build_action_json(transcript, ner_result, intent)\n",
        "    except Exception as e:\n",
        "        json_obj = None\n",
        "\n",
        "    intent_jsons.append(json_obj)\n",
        "\n",
        "df[\"intent_json\"] = intent_jsons\n",
        "\n",
        "# Save results\n",
        "df.to_csv(\"intent_extracted_cleaned.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "# files.download(\"intent_extracted_cleaned.csv\")\n"
      ],
      "metadata": {
        "id": "Qmb1W8IAGEHH"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract rephrased sentence from intent_json using templates\n",
        "def rephrase_from_intent_json(intent, intent_json):\n",
        "    template = intent_templates.get(intent)\n",
        "    if not template or not intent_json:\n",
        "        return None\n",
        "\n",
        "    # Rename keys if needed\n",
        "    mapping = {\n",
        "        \"contact_name\": \"contact_first_name\",\n",
        "        \"search\": \"search string\"\n",
        "    }\n",
        "\n",
        "    for old_key, new_key in mapping.items():\n",
        "        if old_key in intent_json and new_key not in intent_json:\n",
        "            intent_json[new_key] = intent_json[old_key]\n",
        "\n",
        "    try:\n",
        "        return template.format(**intent_json)\n",
        "    except Exception as e:\n",
        "        return f\"שגיאה בפורמט: {e}\"\n",
        "\n",
        "# Create a new column with rephrased sentence\n",
        "df[\"rephrased\"] = df.apply(lambda row: rephrase_from_intent_json(row[\"intent\"], row[\"intent_json\"]), axis=1)\n",
        "\n",
        "# Save the new CSV including rephrased column\n",
        "df.to_csv(\"rephrased_intents.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "files.download(\"rephrased_intents.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "UJ1bZPlfa1za",
        "outputId": "133e72bd-a680-41cd-a365-c9f3dd94cdc2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_ab853002-28d0-4abe-b135-00feb2878da9\", \"rephrased_intents.csv\", 13046)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}